{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc9be6f-f61e-4f3e-8f53-48150e2ad6bd",
   "metadata": {},
   "source": [
    "https://github.com/elsevierlabs-os/clip-image-search/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7cbccf-4a5c-4125-b1cf-293ad39e26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ftfy pyperclip spacy torch torchvision transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19060582-9df2-4c6a-a499-619ec8de679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from requests.exceptions import Timeout\n",
    "\n",
    "# Load the csv file\n",
    "data = pd.read_csv('/Users/shawngraham/Documents/code-experiments/llm-commandline/archaeology-images-ai/csv_data/artifact_images_w_descriptions.csv')\n",
    "\n",
    "# Filter the dataset to content with image_file__uri\n",
    "image_data = data[data['image_file__uri'].notna()]\n",
    "\n",
    "# Reset index before split to ensure unique indices\n",
    "image_data = image_data.reset_index(drop=True)\n",
    "\n",
    "# Randomly select 10% for training, 10% for testing and 80% for validation\n",
    "train_data = image_data.sample(frac=0.001, random_state=42) #small number for now just to get the flow right\n",
    "remaining_data = image_data.drop(train_data.index)\n",
    "test_data = remaining_data.sample(frac=0.001, random_state=42)  # 10% of 90% remaining data\n",
    "remaining_data = remaining_data.drop(test_data.index)\n",
    "validation_data = remaining_data.sample(frac=0.0005, random_state=42)  # 5% of 80% remaining data\n",
    "\n",
    "# Create metadata\n",
    "def create_metadata(data):\n",
    "    data['caption'] = (data['item__earliest'].fillna('').astype(str) + ', ' +\n",
    "                       data['item__latest'].fillna('').astype(str) + ', ' +\n",
    "                       data['context___1'].fillna('').astype(str) + ', ' +\n",
    "                       data['context___2'].fillna('').astype(str) + ', ' +\n",
    "                       data['context___3'].fillna('').astype(str) + ', ' +\n",
    "                       data['Consists of (Label) [https://erlangen-crm.org/current/P45_consists_of]'].fillna('').astype(str) + ', ' +\n",
    "                       data['project_specific_descriptions'].fillna('').astype(str))\n",
    "    return data\n",
    "\n",
    "train_data = create_metadata(train_data)\n",
    "test_data = create_metadata(test_data)\n",
    "validation_data = create_metadata(validation_data)\n",
    "\n",
    "# Create the main directories if they don't exist\n",
    "os.makedirs('ourimages/test/octest', exist_ok=True)\n",
    "os.makedirs('ourimages/training/octraining', exist_ok=True)\n",
    "os.makedirs('ourimages/validation/ocvalidation', exist_ok=True)\n",
    "\n",
    "datasets = [(train_data, 'ourimages/training/octraining/'), \n",
    "            (test_data, 'ourimages/test/octest/'), \n",
    "            (validation_data, 'ourimages/validation/ocvalidation/')]\n",
    "\n",
    "url_errors = []\n",
    "\n",
    "\n",
    "# Download images and save into respective folders\n",
    "for dataset in datasets:\n",
    "    data, folder = dataset\n",
    "    # Initialize 'image' column\n",
    "    data['image'] = \"\"\n",
    "    for index, row in data.iterrows():\n",
    "        url = row['image_file__uri']\n",
    "        extension = url.split('.')[-1]\n",
    "        media_uuid = row['media__uri'].split('/')[-1]\n",
    "        file_name = f'{media_uuid}.{extension}'\n",
    "        # Assign the 'file_name' to the 'image' column of the current row\n",
    "        data.loc[index, 'image'] = file_name\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, timeout=5)\n",
    "            response.raise_for_status()\n",
    "        except (requests.exceptions.RequestException, Timeout):\n",
    "            print(f'An error occurred while fetching: {url}')\n",
    "            url_errors.append(url)\n",
    "            continue\n",
    "\n",
    "        with open(file_path, 'wb') as img_file:\n",
    "            img_file.write(response.content)\n",
    "\n",
    "\n",
    "# Save captions as csv\n",
    "train_data[['image', 'caption']].to_csv('ourimages/training/octraining-Captions.csv', index=False)\n",
    "test_data[['image', 'caption']].to_csv('ourimages/test/octest-captions.txt', sep = \"\\t\", index=False)\n",
    "validation_data[['image', 'caption']].to_csv('ourimages/validation/ocvalidation-Captions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237615b0-6fd6-4012-b603-7c587767f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the original repo saves training, validation as csv. But it's apparent in clip_dataset.py that\n",
    "# they used /t as sepa\n",
    "\n",
    "def replace_comma_with_tab(file_path):\n",
    "    # Read the csv file, treat everything inside double quotes as a single field\n",
    "    data = pd.read_csv(file_path, quotechar='\"')\n",
    "\n",
    "    # Remove commas from the 'caption' column\n",
    "    data['caption'] = data['caption'].str.replace(',', '')\n",
    "\n",
    "    # Write the data back into the file with a tab as the separator\n",
    "    data.to_csv(file_path, sep='\\t', index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "replace_comma_with_tab('ourimages/training/octraining-Captions.csv')\n",
    "replace_comma_with_tab('ourimages/validation/ocvalidation-Captions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32912aec-c26c-473e-b6bb-018e2dcdbe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shawngraham/Documents/code-experiments/llm-commandline/archaeology-images-ai/retraining-2/vectorize_images.py\", line 52, in <module>\n",
      "    \"test\": ImageCaptionDataset(\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shawngraham/Documents/code-experiments/llm-commandline/archaeology-images-ai/retraining-2/clip_dataset.py\", line 19, in __init__\n",
      "    image_id, caption = line.strip().split('\\t')\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 1)\n"
     ]
    }
   ],
   "source": [
    "!python vectorize_images.py baseline output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f06901a-943f-4fc9-b684-7897c02f8c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/shawngraham/Documents/code-experiments/llm-commandline/archaeology-images-ai/retraining-2/train.py\", line 86, in <module>\n",
      "    config = yaml.load(fcfg)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "TypeError: load() missing 1 required positional argument: 'Loader'\n"
     ]
    }
   ],
   "source": [
    "!python train.py train_configs/run1.cfg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
