{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b0f6b7-8028-4a41-8fd0-b49e6a495983",
   "metadata": {},
   "source": [
    "# Current, Best Approach to Fine-Tuning CLIP\n",
    "\n",
    "This notebook will keep the best, most current approach to fine-tuning the CLIP model with data from Open Context and other archaeological sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda41c98-76ef-48cd-88f5-534054a1f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.error import HTTPError, URLError\n",
    "from sklearn.model_selection import train_test_split\n",
    "import concurrent.futures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc50852-3a41-427a-ae66-833e0986ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image_convert_to_jpg(uri, folder, uuid, caption):\n",
    "    \"\"\"Downloads an image, makes sure it is saved as a jpeg\"\"\"\n",
    "    uuid = str(uuid)\n",
    "    new_image_path = os.path.join(folder, f'{uuid}.jpg')\n",
    "    parse_object = urlparse(uri)\n",
    "    _, ext_from_url = os.path.splitext(parse_object.path)\n",
    "    if isinstance(ext_from_url, bytes):\n",
    "        ext_from_url = ext_from_url.decode(\"utf-8\") \n",
    "    ext_from_url = ext_from_url.lower().replace('.', '')\n",
    "    if ext_from_url in ['jpg', 'jpeg']:\n",
    "        try:\n",
    "            urlretrieve(uri, new_image_path)\n",
    "            return {\"image\": new_image_path, \"caption\": caption}\n",
    "        except (HTTPError, URLError) as error:\n",
    "            print(f\"Download error for URL {uri}\")\n",
    "            print(error)\n",
    "            return None\n",
    "    # Not a jpg\n",
    "    download_ok = None\n",
    "    try:\n",
    "        response = requests.get(uri)\n",
    "        response.raise_for_status()\n",
    "        # Check the file type (extension) and convert to JPG if needed\n",
    "        content_type = response.headers['Content-Type']\n",
    "        if content_type.startswith('image/'):\n",
    "            extension = content_type.split('/')[1]\n",
    "            if extension.lower() not in ('jpg', 'jpeg'):\n",
    "                img = Image.open(BytesIO(response.content))\n",
    "                img.save(new_image_path, 'JPEG')\n",
    "                print(f\"Converted and saved {uri} as JPG: {new_image_path}\")\n",
    "                download_ok = True\n",
    "            else:\n",
    "                with open(new_image_path, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "                print(f\"Downloaded and saved {uri} as JPG: {new_image_path}\")\n",
    "                download_ok = True\n",
    "        else:\n",
    "            print(f\"Skipping {uri} - Not an image\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {url}: {str(e)}\")\n",
    "        download_ok = False\n",
    "    if not download_ok:\n",
    "        return None\n",
    "    return {\"image\": new_image_path, \"caption\": caption}\n",
    "\n",
    "\n",
    "def download_and_rename(row, folder):\n",
    "    \"\"\"Downloads an image file and saves with the media item UUID as the filename\"\"\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    uri = row['image_file__uri']\n",
    "    # Check if uri exists and is a string\n",
    "    if uri and isinstance(uri, str):\n",
    "        uuid = row['media__uuid']\n",
    "        caption = row['caption']\n",
    "        return download_image_convert_to_jpg(uri, folder, uuid, caption)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Writing to 'jsonl' files\n",
    "def write_to_jsonl(new_data, jsonl_file):\n",
    "    \"\"\"Makes JSONL file with new_data\"\"\"\n",
    "    with open(jsonl_file, 'w') as file:\n",
    "        for json_dict in new_data:\n",
    "            line = json.dumps(json_dict)\n",
    "            file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a2b3b8-f54a-4866-aa8b-2095694c8fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download error for URL https://artiraq.org/static/opencontext/poggio-civitate/preview/photos/20000134FRONT.jpg\n",
      "HTTP Error 404: Not Found\n",
      "Download error for URL https://artiraq.org/static/opencontext/poggio-civitate/preview/photos/20050166TOP.jpg\n",
      "HTTP Error 404: Not Found\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/14-1607-id1447-1.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/3d09dd21-d076-43fa-9d5e-928132f6f0b4.jpg\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/027695-id1996-3.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/73eec343-15ab-4929-9f20-257d4cf9fd18.jpg\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/14-1050-id627-2.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/df8addcd-968b-4d9e-bc67-00bd542026a0.jpg\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/18477-id84-1.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/c7ef5961-b934-4fde-8c42-5f8107bf7c06.jpg\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/158-id487.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/f98aff24-24e5-4937-86a2-a7697aa30753.jpg\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/1004-id185-3.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/42d010bd-1d61-40b6-b159-37806cc6b356.jpg\n",
      "Download error for URL https://artiraq.org/static/opencontext/poggio-civitate/preview/photos/19850026BACK.jpg\n",
      "HTTP Error 404: Not Found\n",
      "Download error for URL https://artiraq.org/static/opencontext/poggio-civitate/preview/photos/20020071PROFILE.jpg\n",
      "HTTP Error 404: Not Found\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/14-1156-id1798-1.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/87c09c06-3835-4ba7-a156-8659b938cda7.jpg\n",
      "Download error for URL https://iiif.archivelab.org/iiif/opencontext-22-d-8-58-18-1-p-2jpg/full/675,/0/default.jpg\n",
      "HTTP Error 404: NOT FOUND\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/20-1744-id1280.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/e5dbddbe-d3b7-4f60-a586-0bd984ce5d5c.jpg\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/16-4-1415-id1775-2.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/89007214-6966-4d7d-86dc-a5c7f00c3716.jpg\n",
      "Download error for URL https://artiraq.org/static/opencontext/poggio-civitate/preview/photos/19840154FRONT.jpg\n",
      "HTTP Error 404: Not Found\n",
      "Download error for URL https://artiraq.org/static/opencontext/poggio-civitate/preview/photos/20030130PROFILE.jpg\n",
      "HTTP Error 404: Not Found\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/431-id383-2.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/3b0bb288-ee50-41bc-aac9-bc63e85d8281.jpg\n",
      "Download error for URL https://artiraq.org/static/opencontext/poggio-civitate/preview/photos/20020051FRONT.jpg\n",
      "HTTP Error 404: Not Found\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/16-4-1415-id1775-1.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/19139f7c-4c84-4e13-ad9a-716ac6674130.jpg\n",
      "Download error for URL https://artiraq.org/static/opencontext/poggio-civitate/preview/photos/20030050BACK.jpg\n",
      "HTTP Error 404: Not Found\n",
      "Download error for URL https://artiraq.org/static/opencontext/poggio-civitate/preview/photos/20020028TOP.jpg\n",
      "HTTP Error 404: Not Found\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/16-4-1372-id1784-1.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/42bf8501-1c3c-4dbf-ba90-bcca0ababb8c.jpg\n",
      "Downloaded and saved https://artiraq.org/static/opencontext/domuztepe/preview/coins/dt5140/dt5140;ob1.JPG as JPG: /home/ekansa/github/archaeology-images-ai/files/training/d56140f6-8059-4f3a-d177-eaf7922cdf6b.jpg\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/13-4131-id1803.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/6403fae6-e089-495a-95d6-7430a7041c4b.jpg\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/027463-id2030-2.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/6a7e9837-efc3-48b5-8a57-252a22ce3b8b.jpg\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/14-1168-id747-1.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/baf61409-d6cc-448f-a029-7fa47d46db4b.jpg\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/13-5750-id1099-1.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/f2275188-05a5-4ddd-a8ef-794bf29c092a.jpg\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/20-1738-id1104-2.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/5ee8dc1d-e7da-4042-a6bc-001211f009bf.jpg\n",
      "Converted and saved https://artiraq.org/static/opencontext/kerma-amulets/preview/027015-id1968.png as JPG: /home/ekansa/github/archaeology-images-ai/files/training/dc4c30aa-7da3-4bee-8e8b-97fdcc7c699d.jpg\n",
      "Download error for URL https://artiraq.org/static/opencontext/poggio-civitate/preview/photos/19950017SIDEb.jpg\n",
      "HTTP Error 404: Not Found\n"
     ]
    }
   ],
   "source": [
    "# Get the root_path for this jupyter notebook repo.\n",
    "repo_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "\n",
    "data_path = os.path.join(repo_path, 'json_data', 'artifact_images_w_sentence_captions.json')\n",
    "df = pd.read_json(data_path)\n",
    "\n",
    "# Change these as desired\n",
    "TRAIN_SIZE = 50000\n",
    "TEST_SIZE = 5000\n",
    "\n",
    "train_data_file = os.path.join(repo_path, 'files', 'train.json')\n",
    "test_data_file = os.path.join(repo_path, 'files', 'test.json')\n",
    "\n",
    "# If we don't have a train_data_file or a test data file, go out and make them!\n",
    "if not os.path.exists(train_data_file) or not os.path.exists(test_data_file):\n",
    "    # Separate out a training dataframe (train_df), a test dataframe (test_df)\n",
    "    train_df, rem_df = train_test_split(df, train_size=TRAIN_SIZE, random_state=42)\n",
    "    test_df = rem_df.sample(TEST_SIZE, random_state=42)\n",
    "    \n",
    "    train_files = [os.path.join(repo_path, 'files', 'training'),]\n",
    "    test_files = [os.path.join(repo_path, 'files', 'testing'),]\n",
    "    \n",
    "    train_data_file = os.path.join(repo_path, 'files', 'train.json')\n",
    "    test_data_file = os.path.join(repo_path, 'files', 'test.json')\n",
    "    \n",
    "    # Process train and test data\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        train_data = list(executor.map(download_and_rename, [row for _, row in train_df.iterrows()], train_files*len(train_df)))\n",
    "        test_data = list(executor.map(download_and_rename, [row for _, row in test_df.iterrows()], test_files*len(test_df)))\n",
    "    \n",
    "    write_to_jsonl(train_data, train_data_file)\n",
    "    write_to_jsonl(test_data, test_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f506e23-39cd-4785-94dc-4d948919d0a0",
   "metadata": {},
   "source": [
    "Now that we have the training and testing data files and the image files, let's train the CLIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a154cfe6-b7e4-43b7-813b-50cdd653ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision datasets Pillow\n",
    "!pip install -q git+https://github.com/huggingface/transformers\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2888efeb-87ed-4432-9cb2-493ae58c094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loading it back in\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"json\", data_files=train_data_file)\n",
    "print(f\"first image: {dataset['train'][0]['image']}, caption: '{dataset['train'][0]['caption']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a11702f-9bb3-4d4c-a7af-7ee52bddbf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/damian0815/finetune-clip-huggingface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc460e-93c9-4d50-b72a-172e0a6987ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id =  \"openai/clip-vit-base-patch32\" # this was the clip version for stable diffusion 1.5\n",
    "#repo_id = \"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\" # this was the clip version for stable diffusion 2.0 onwards\n",
    "# however, using it requires more memory than I have available. More than what's available free tier google colab too.\n",
    "\n",
    "result_output_folder = os.path.join(repo_path, 'results')\n",
    "\n",
    "batch_size = 100\n",
    "num_train_epochs = 8\n",
    "max_token_seq_length = 77 # probably should be 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2523a64d-2f24-461d-b5ab-50f9a4426324",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Finetuning {repo_id} for {num_train_epochs} epochs with batch size {batch_size}, and then saving output to {result_output_folder}.\")\n",
    "!python -W ignore finetune-clip-huggingface/huggingface_finetune_clip.py \\\n",
    "    --output_dir {result_output_folder} \\\n",
    "    --model_name_or_path {repo_id} \\\n",
    "    --train_file {train_data_file} \\\n",
    "    --image_column image \\\n",
    "    --overwrite_output_dir=True \\\n",
    "    --max_seq_length={max_token_seq_length} \\\n",
    "    --num_train_epochs={num_train_epochs} \\\n",
    "    --caption_column caption \\\n",
    "    --remove_unused_columns=False \\\n",
    "    --do_train \\\n",
    "    --per_device_train_batch_size={batch_size} \\\n",
    "    --learning_rate=\"5e-5\" --warmup_steps=\"2\" --weight_decay 0.2\n",
    "print(\"--\\nDONE\")\n",
    "print(f\"If it worked, trained data should be in {result_output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2bef16-28bd-4825-8a99-9fcc3d7d1b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8193aabc-d1d8-40af-94f6-5a69b7899625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
